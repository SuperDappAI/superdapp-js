import { SuperDappAgent, createBotConfig } from '../../src';

/**
 * Multi-Provider AI Example
 * 
 * This example demonstrates the model-agnostic capabilities of the SuperDapp AI integration.
 * The same code works with different providers - just change environment variables!
 * 
 * Prerequisites:
 * 1. Install AI dependencies for your chosen provider:
 *    - OpenAI: npm install ai @ai-sdk/openai
 *    - Anthropic: npm install ai @ai-sdk/anthropic  
 *    - Google: npm install ai @ai-sdk/google
 * 
 * 2. Set environment variables for your chosen provider:
 * 
 *    For OpenAI:
 *    - AI_PROVIDER=openai
 *    - AI_MODEL=gpt-4
 *    - AI_API_KEY=sk-your-openai-api-key
 * 
 *    For Anthropic:
 *    - AI_PROVIDER=anthropic
 *    - AI_MODEL=claude-3-sonnet-20240229
 *    - AI_API_KEY=sk-ant-your-anthropic-api-key
 * 
 *    For Google:
 *    - AI_PROVIDER=google
 *    - AI_MODEL=gemini-pro
 *    - AI_API_KEY=your-google-ai-api-key
 * 
 * 3. Run: npx ts-node examples/ai/multi-provider-example.ts
 */

async function main() {
  console.log('üöÄ Starting Multi-Provider AI Agent...');

  try {
    // Create agent - it will use whatever provider is configured
    const agent = new SuperDappAgent(createBotConfig());

    // Show current configuration
    agent.addCommand('/status', async (message, replyMessage, roomId) => {
      const config = agent.getConfig();
      
      if (!config.ai) {
        await agent.sendConnectionMessage(roomId, '‚ùå AI is not configured. Run `superagent configure` to set up AI integration.');
        return;
      }

      const statusMessage = `ü§ñ **AI Configuration Status**

**Provider:** ${config.ai.provider || 'Not set'}
**Model:** ${config.ai.model || 'Not set'}
**API Key:** ${config.ai.apiKey ? '***' + config.ai.apiKey.slice(-4) : 'Not set'}
**Base URL:** ${config.ai.baseUrl || 'Default'}

**Provider Capabilities:**
${getProviderInfo(config.ai.provider)}

To switch providers, change your environment variables and restart the agent.`;

      await agent.sendConnectionMessage(roomId, statusMessage);
    });

    // Universal text generation - works with any provider
    agent.addCommand('/generate', async (message, replyMessage, roomId) => {
      const prompt = message.body.m?.body?.split(' ').slice(1).join(' ');
      if (!prompt) {
        await agent.sendConnectionMessage(roomId, 'Please provide a prompt! Usage: /generate Explain quantum physics');
        return;
      }

      try {
        const config = agent.getConfig();
        console.log(`ü§ñ Generating text using ${config.ai?.provider || 'unknown'} - ${config.ai?.model || 'unknown'}`);
        
        const aiClient = agent.getAiClient();
        const response = await aiClient.generateText(prompt, {
          temperature: 0.7,
          maxTokens: 500
        });
        
        await agent.sendConnectionMessage(roomId, `**Generated by ${config.ai?.provider?.toUpperCase()} ${config.ai?.model}:**\n\n${response}`);
      } catch (error) {
        console.error('Generation Error:', error);
        await agent.sendConnectionMessage(roomId, 'Sorry, I had trouble generating that response.');
      }
    });

    // Compare responses (if you want to test multiple providers)
    agent.addCommand('/compare', async (message, replyMessage, roomId) => {
      const prompt = message.body.m?.body?.split(' ').slice(1).join(' ');
      if (!prompt) {
        await agent.sendConnectionMessage(roomId, 'Please provide a prompt to compare! Usage: /compare Write a haiku about technology');
        return;
      }

      try {
        const config = agent.getConfig();
        const currentProvider = config.ai?.provider || 'unknown';
        
        await agent.sendConnectionMessage(roomId, `ü§ñ Generating response using **${currentProvider.toUpperCase()}**...\n\n*To compare with other providers, change your AI_PROVIDER environment variable and restart.*`);
        
        const aiClient = agent.getAiClient();
        const response = await aiClient.generateText(prompt, {
          temperature: 0.7,
          maxTokens: 300
        });
        
        await agent.sendConnectionMessage(roomId, `**${currentProvider.toUpperCase()} Response:**\n\n${response}\n\n*Try the same prompt with different providers to see how they differ!*`);
      } catch (error) {
        console.error('Compare Error:', error);
        await agent.sendConnectionMessage(roomId, 'Sorry, I had trouble generating that comparison.');
      }
    });

    // Conversation that adapts to provider strengths
    agent.addCommand('/chat', async (message, replyMessage, roomId) => {
      const userMessage = message.body.m?.body?.split(' ').slice(1).join(' ');
      if (!userMessage) {
        await agent.sendConnectionMessage(roomId, 'Please provide a message! Usage: /chat Hello, how are you?');
        return;
      }

      try {
        const config = agent.getConfig();
        const provider = config.ai?.provider;
        
        // Adapt system prompt based on provider strengths
        let systemPrompt = "You are a helpful AI assistant.";
        
        switch (provider) {
          case 'openai':
            systemPrompt = "You are a versatile AI assistant powered by OpenAI. You're good at creative tasks, coding, and general conversations. Be helpful and engaging.";
            break;
          case 'anthropic':
            systemPrompt = "You are Claude, created by Anthropic. You excel at thoughtful analysis, reasoning, and nuanced discussions. Be helpful, honest, and acknowledge uncertainty when appropriate.";
            break;
          case 'google':
            systemPrompt = "You are Gemini, Google's AI assistant. You're knowledgeable and helpful across many domains. Provide clear, informative responses.";
            break;
        }

        const aiClient = agent.getAiClient();
        const conversation = [
          { role: "system" as const, content: systemPrompt },
          { role: "user" as const, content: userMessage }
        ];

        const response = await aiClient.generateText(conversation, {
          temperature: 0.8,
          maxTokens: 400
        });
        
        await agent.sendConnectionMessage(roomId, response);
      } catch (error) {
        console.error('Chat Error:', error);
        await agent.sendConnectionMessage(roomId, 'Sorry, I encountered an issue with the chat.');
      }
    });

    // Provider-specific optimal tasks
    agent.addCommand('/optimal', async (message, replyMessage, roomId) => {
      const config = agent.getConfig();
      const provider = config.ai?.provider;

      const suggestions = {
        openai: [
          '/generate Write a Python function to sort a list',
          '/generate Create a marketing slogan for a coffee shop',
          '/generate Explain the concept of recursion',
          '/chat How do I improve my coding skills?'
        ],
        anthropic: [
          '/generate Analyze the ethical implications of AI in hiring',
          '/generate Write a thoughtful essay on climate change',
          '/generate Compare different philosophical approaches to consciousness',
          '/chat What are the key considerations in moral decision-making?'
        ],
        google: [
          '/generate Summarize the latest developments in renewable energy',
          '/generate Create a travel itinerary for Japan',
          '/generate Explain how search engines work',
          '/chat What are the benefits of machine learning?'
        ]
      };

      const providerSuggestions = suggestions[provider as keyof typeof suggestions] || [
        '/generate Tell me about artificial intelligence',
        '/chat Hello, how can you help me?'
      ];

      const message_text = `üéØ **Optimal Tasks for ${provider?.toUpperCase() || 'Current Provider'}**

Here are some tasks that work great with ${provider || 'your current provider'}:

${providerSuggestions.map(cmd => `‚Ä¢ \`${cmd}\``).join('\n')}

**Try these commands to see what ${provider || 'your AI provider'} does best!**`;

      await agent.sendConnectionMessage(roomId, message_text);
    });

    // Help command
    agent.addCommand('/help', async (message, replyMessage, roomId) => {
      const config = agent.getConfig();
      const provider = config.ai?.provider?.toUpperCase() || 'AI';

      const helpText = `ü§ñ **Multi-Provider AI Agent**

**Current Provider:** ${provider}
**Model:** ${config.ai?.model || 'Not configured'}

**Universal Commands:**
‚Ä¢ \`/status\` - Show AI configuration and provider info
‚Ä¢ \`/generate <prompt>\` - Generate text with current provider
‚Ä¢ \`/chat <message>\` - Have a conversation
‚Ä¢ \`/compare <prompt>\` - Generate and show provider info
‚Ä¢ \`/optimal\` - See optimal tasks for current provider
‚Ä¢ \`/help\` - Show this help

**Key Features:**
‚úÖ **Model Agnostic** - Same code, different providers
‚úÖ **Easy Switching** - Change via environment variables
‚úÖ **Provider Optimization** - Adapts to provider strengths
‚úÖ **Configuration Status** - Always know what's configured

**Switch Providers:**
1. Install provider SDK: \`npm install ai @ai-sdk/[provider]\`
2. Update environment: \`AI_PROVIDER=openai|anthropic|google\`
3. Set model and API key
4. Restart agent

**Examples:**
‚Ä¢ \`/generate Write a poem about space exploration\`
‚Ä¢ \`/chat What makes you unique as an AI?\`
‚Ä¢ \`/compare Explain quantum computing in simple terms\``;

      await agent.sendConnectionMessage(roomId, helpText);
    });

    // Initialize agent
    await agent.initialize();
    
    const config = agent.getConfig();
    const provider = config.ai?.provider?.toUpperCase() || 'UNKNOWN';
    const model = config.ai?.model || 'unknown';
    
    console.log('‚úÖ Multi-provider AI agent initialized successfully!');
    console.log(`ü§ñ Current AI Provider: ${provider} (${model})`);
    console.log('üîó Available commands: /status, /generate, /chat, /compare, /optimal, /help');
    console.log('üí° Tip: Try different providers by changing AI_PROVIDER environment variable');

  } catch (error) {
    if (error.message.includes('AI configuration')) {
      console.error('‚ùå AI Configuration Error:', error.message);
      console.error('\nPlease configure an AI provider:');
      console.error('\nüîπ OpenAI:');
      console.error('  AI_PROVIDER=openai');
      console.error('  AI_MODEL=gpt-4');
      console.error('  AI_API_KEY=sk-your-openai-api-key');
      console.error('\nüîπ Anthropic:');
      console.error('  AI_PROVIDER=anthropic');  
      console.error('  AI_MODEL=claude-3-sonnet-20240229');
      console.error('  AI_API_KEY=sk-ant-your-anthropic-api-key');
      console.error('\nüîπ Google:');
      console.error('  AI_PROVIDER=google');
      console.error('  AI_MODEL=gemini-pro'); 
      console.error('  AI_API_KEY=your-google-ai-api-key');
      console.error('\nOr run: superagent configure');
    } else {
      console.error('‚ùå Agent initialization failed:', error.message);
    }
    process.exit(1);
  }
}

function getProviderInfo(provider?: string): string {
  switch (provider) {
    case 'openai':
      return `‚Ä¢ **Strengths:** Versatile, creative tasks, coding, conversational
‚Ä¢ **Models:** GPT-4, GPT-3.5 Turbo, GPT-4 Turbo
‚Ä¢ **Best for:** Code generation, creative writing, general Q&A`;

    case 'anthropic':
      return `‚Ä¢ **Strengths:** Reasoning, analysis, long-form writing, ethics
‚Ä¢ **Models:** Claude 3 Opus, Sonnet, Haiku
‚Ä¢ **Best for:** Research, essays, philosophical discussions`;

    case 'google':
      return `‚Ä¢ **Strengths:** Knowledge synthesis, multimodal, factual responses
‚Ä¢ **Models:** Gemini Pro, Gemini Pro Vision
‚Ä¢ **Best for:** Information synthesis, travel planning, explanations`;

    default:
      return `‚Ä¢ Provider-specific capabilities will be shown once configured
‚Ä¢ Each provider has unique strengths and optimal use cases`;
  }
}

// Run if executed directly
if (require.main === module) {
  main().catch(console.error);
}

export default main;